# ylog - GitHub PR History to Context CLI Tool

## Project Overview
A TypeScript CLI tool that converts GitHub PR history into structured context for LLMs.

### Core Functionality
1. Auto-detect GitHub repo from git remote
2. Fetch PR data via GitHub CLI (`gh`)
3. Summarize PRs using AI (Ollama or Anthropic via Vercel AI SDK)  
4. Store results in local SQLite database (./ylog/prs.db)

## Architecture & Design Principles

### Project Structure (Simplified for MVP)
```
src/
├── cli/           # Commands (init, sync)
├── core/          # Main business logic  
├── adapters/      # aiClient.ts, ghClient.ts
├── storage/       # SQLite database operations
└── types/         # Type definitions
```

### Key Technologies
- **AI Integration**: Vercel AI SDK (`ai` + `@ai-sdk/anthropic` + `ollama-ai-provider`)
- **Database**: better-sqlite3 for local storage
- **CLI**: commander.js for command interface
- **Validation**: Zod for configuration validation
- **Build**: tsup + tsx for development
- **Testing**: vitest with simple approach (unit tests + one integration test)

## Code Style Guidelines

### TypeScript Standards
- Use `type` declarations over `interface` declarations
- Target Node.js 20+ (ES2022, NodeNext modules)
- Use `.js` extensions in relative imports (ES module standard)
- All functions should have explicit return types

### Naming Conventions
- **Folders**: kebab-case (e.g., `src/adapters/`)
- **Files**: camelCase (e.g., `aiClient.ts`)
- **Variables/Functions**: camelCase
- **Types**: PascalCase
- **Constants**: SCREAMING_SNAKE_CASE

### Programming Paradigm
- **Functional programming preferred** over OOP
- **No classes or inheritance** - use pure functions and composition
- **No `this` keyword**
- **No global state** - pass execution context as parameters
- **Simple error handling** - try/catch instead of Result patterns for MVP
- **Minimal dependency injection** - only where needed for testing

### Code Organization
- Each file should have a companion `.test.ts` file in the same directory
- Keep functions pure when possible
- Use composition over inheritance
- Prefer explicit over implicit behavior

## Configuration Management

### Default Configuration Structure
```typescript
type YlogConfig = {
  github?: {
    repo?: string; // Auto-detect from git remote if not provided
    throttleRpm?: number; // Default 100
  };
  ai: {
    provider: 'ollama' | 'anthropic';
    model: string;
    apiKey?: string; // For Anthropic
    endpoint?: string; // For Ollama, default 'http://localhost:11434'
    maxTokens?: number; // Default 100
  };
  concurrency?: number; // Default 10
  outputDir?: string; // Default './ylog' (contains prs.db + HISTORY.md)
  generateContextFiles?: boolean; // Default true - create .ylog files
  contextFileThreshold?: number; // Default 3 - min PRs to generate .ylog
  historyMonths?: number; // Default 6 - timeframe for contextual files
  cacheDir?: string; // Default '~/.ylog-cache'
  diffMaxBytes?: number; // Default 1MB
};
```

## Data Models

### Enhanced SQLite Schema
```sql
CREATE TABLE prs (
  -- Core GitHub data
  number INTEGER PRIMARY KEY,
  title TEXT,
  body TEXT, -- Store original for re-processing
  author TEXT,
  created_at TEXT,
  merged_at TEXT,
  
  -- Rich metadata
  reviewers TEXT, -- JSON: ["alice", "bob"]
  labels TEXT, -- JSON: ["bug", "feature"]
  linked_issues TEXT, -- JSON: [123, 456]
  files_changed TEXT, -- JSON with file paths and stats
  base_branch TEXT,
  head_branch TEXT,
  
  -- LLM-generated content
  why TEXT, -- AI summary focusing on "why"
  business_impact TEXT, -- Why was this needed?
  technical_changes TEXT, -- What was implemented?
  areas TEXT, -- Affected code areas: ["src/auth", "infra"]
  
  -- Quality & provenance
  llm_model TEXT, -- "anthropic/claude-3" or "ollama/mistral"
  confidence_score REAL, -- 0.0-1.0 if available
  human_reviewed BOOLEAN DEFAULT FALSE,
  schema_version INTEGER DEFAULT 1,
  processed_at TEXT,
  
  -- Legacy stats
  diff_add INTEGER,
  diff_del INTEGER,
  comments INTEGER
);

-- Indexes for common queries
CREATE INDEX idx_author ON prs(author);
CREATE INDEX idx_areas ON prs(areas);
CREATE INDEX idx_labels ON prs(labels);
CREATE INDEX idx_merged_at ON prs(merged_at);
```

### GitHub PR Data (Raw Cache)
```typescript
type RawPR = {
  number: number;
  title: string;
  body: string;
  author: { login: string };
  mergedAt: string;
  files: Array<{ path: string }>;
  comments: Array<{ body: string }>;
  patch: string; // truncated if > diffMaxBytes
};
```

## Hybrid Output Strategy

ylog generates both structured data and human-readable context:

1. **SQLite Database** (`./ylog/prs.db`): Structured, queryable data for tools and rich analysis
2. **Contextual Files** (`src/auth/.ylog`, `infrastructure/.ylog`): Human-readable history files placed near relevant code  
3. **Central Overview** (`./ylog/HISTORY.md`): Optional chronological summary

### Example Contextual File (`src/auth/.ylog`)
```markdown
<!-- Auto-generated by ylog. Do not edit. Regenerate with: ylog sync --area src/auth -->

# Development History: src/auth/

## Recent Changes (Last 6 months)

**🔐 JWT Token Migration** - [PR #1234](link) by @alice • 2024-03-01
*Introduces JWT-backed sessions to prepare for multi-region deployments. Replaces cookie-based auth with stateless tokens.*

**🐛 Fix Session Timeout** - [PR #1189](link) by @bob • 2024-02-15
*Resolves race condition in session cleanup that caused users to be logged out unexpectedly during high traffic.*

## Key Contributors
- @alice (2 PRs): JWT migration, performance improvements
- @bob (1 PR): Session timeout fixes

---
*Generated from ylog database • [Query this area](ylog show src/auth)*
```

## Implementation Guidelines

### AI Integration (Vercel AI SDK)
```typescript
import { generateText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';
import { createOllama } from 'ollama-ai-provider';

// Unified interface for both providers
const createAIClient = (config: YlogConfig['ai']) => {
  if (config.provider === 'anthropic') {
    return anthropic({ apiKey: config.apiKey })(config.model);
  }
  
  const ollama = createOllama({
    baseURL: config.endpoint || 'http://localhost:11434/api',
  });
  
  return ollama(config.model);
};

// Generate multiple summary types
const generateSummaries = async (prData: RawPR) => {
  const { text } = await generateText({
    model: createAIClient(config.ai),
    prompt: buildStructuredPrompt(prData),
    maxTokens: config.ai.maxTokens || 100,
  });
  
  return parseSummaryFields(text); // Extract why, business_impact, technical_changes
};
```

### SQLite Operations
```typescript
import Database from 'better-sqlite3';

// ACID transactions eliminate need for atomic file operations
// Use prepared statements for performance
// Simple queries: SELECT MAX(number) FROM prs for resumability
```

### GitHub Integration
```typescript
// Use execa to call gh CLI
// Auto-detect repo: git remote get-url origin
// Rate limiting with exponential backoff
// Cache raw PR data outside repo (in ~/.ylog-cache)
```

## Error Handling Strategy

### Pre-flight Checks (Fail Fast)
- Ensure `gh` CLI installed and authenticated
- Ensure AI provider accessible (Ollama running or Anthropic API key valid)
- Auto-detect GitHub repo from git remote
- Verify Node ≥ 20

### Runtime Error Handling
- Simple try/catch blocks (no Result pattern for MVP)
- Idempotent operations - safe to restart anytime
- Graceful degradation on network failures
- Comprehensive logging for debugging

## Testing Approach (Simplified for MVP)

### Testing Strategy
- **Unit tests**: Core logic with mocked dependencies
- **One integration test**: Full sync with real OSS repo (e.g., microsoft/vscode)
- **No complex test matrices** - keep it simple for weekend shipping

### Test Organization
- Tests live next to source files (`file.ts` + `file.test.ts`)
- Use vitest for fast test execution
- Mock external dependencies (gh CLI, AI providers, file system)

## Development Workflow

### Commands
```bash
npm run dev           # Run CLI locally
npm run dev:watch     # Development with auto-reload
npm run test          # Unit tests
npm run test:integration # Integration test
npm run lint          # oxlint (fast Rust-based linting)
npm run typecheck     # TypeScript validation
npm run ci            # Full pipeline: lint + typecheck + test + build
```

### Git Workflow
- Pre-commit hooks run lint + typecheck + test automatically
- Use conventional commit messages when possible
- Keep commits focused and atomic

## Security Considerations

- **API keys**: Store in environment variables, not config files
- **Raw cache**: Lives outside repo to avoid accidental commits
- **Summaries**: May leak sensitive insights - warn users appropriately

## Future Extensibility

### Phase 2+ Features (Not for MVP)
- Query interface: "show me all auth-related PRs" via SQL
- Additional AI providers (OpenAI, etc.)
- Vector embeddings for semantic search
- Markdown wiki generation per area
- VS Code integration

### Design for Extension
- Vercel AI SDK makes adding new providers trivial
- SQLite enables rich querying capabilities
- Modular architecture supports feature additions

## Common Patterns to Follow

### Configuration Loading
```typescript
// Use Zod for validation with detailed error messages
// Support environment variable substitution
// Provide sensible defaults for optional fields
```

### Async Operations
```typescript
// Use p-limit for bounded concurrency
// Handle rate limiting with exponential backoff
// Make all operations resumable and idempotent
```

### Prompt Engineering
```typescript
// Focus prompts on "WHY" with enough "WHAT" for code linking
// Handle minimal PR descriptions gracefully
// Keep prompts concise to respect token limits
```

## Performance Considerations

- **SQLite**: Fast local database with ACID properties
- **oxlint**: ~100x faster than ESLint for linting
- **Vercel AI SDK**: Optimized for performance and reliability
- **Bounded concurrency**: Respect API rate limits
- **Caching**: Avoid re-fetching already processed PRs

## Dependencies Management

### Core Dependencies
- `ai`, `@ai-sdk/anthropic`, `ollama-ai-provider` for AI
- `better-sqlite3` for database  
- `commander` for CLI
- `zod` for validation
- `execa` for subprocess execution
- `p-limit` for concurrency control

### Development Dependencies
- `oxlint` for fast linting
- `vitest` for testing
- `tsx` for development
- `tsup` for building
- `husky` for git hooks

Keep dependencies minimal and well-justified. Prefer battle-tested libraries over cutting-edge ones for stability.